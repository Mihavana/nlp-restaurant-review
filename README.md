# üçΩÔ∏è Analyse de l'Attention Port√©e aux Aspects Cl√©s d'un Restaurant

> **Projet NLP ‚Äî M1 S8 | Institut National Sup√©rieur d'Informatique**

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-EE4C2C?logo=pytorch)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-FFD21E?logo=huggingface)
![Streamlit](https://img.shields.io/badge/Streamlit-1.29.0-FF4B4B?logo=streamlit)
![Sklearn](https://img.shields.io/badge/Scikit--Learn-1.3.2-F7931E?logo=scikit-learn)
![License](https://img.shields.io/badge/License-MIT-green)

---

## üë§ Informations

| | |
|---|---|
| **Auteur** | RAHOLDINA FIARA Anjara Mihavana |
| **Niveau** | M1 S8 |
| **Matricule** | 55/M1 |
| **√âtablissement** | Institut National Sup√©rieur d'Informatique |
| **Date** | F√©vrier 2026 |

---

## üìã Description du Projet

Ce projet impl√©mente et compare **trois approches NLP** pour l'**Aspect-Based Sentiment Analysis (ABSA)** appliqu√©e aux avis de restaurants.

L'objectif est d'analyser automatiquement :
- üéØ **Les aspects mentionn√©s** dans un avis (nourriture, service, ambiance, prix, propret√©)
- üí¨ **Le sentiment associ√©** √† chaque aspect (positif, n√©gatif, neutre)
- üìä **L'attention port√©e** √† chaque aspect

---

## ü§ñ Les 3 Mod√®les Impl√©ment√©s

| # | Mod√®le | Accuracy | F1-Score (Weighted) | Technologie |
|---|--------|----------|---------------------|-------------|
| 1 | **Baseline ‚Äî Logistic Regression** | 58.50% | 50.92% | Scikit-learn + TF-IDF |
| 2 | **Deep Learning ‚Äî BiLSTM + Attention** | 71.00% | 50.92% | PyTorch |
| 3 | **Transformer ‚Äî BERT Fine-tuned** ‚≠ê | 72.67% | 62.82% | Hugging Face |

---

## üìÇ Structure du Projet

```
restaurant-nlp/
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Baseline_ML.ipynb       # Mod√®le 1 : Logistic Regression
‚îÇ   ‚îú‚îÄ‚îÄ 02_BiLSTM.ipynb            # Mod√®le 2 : BiLSTM + Attention
‚îÇ   ‚îî‚îÄ‚îÄ 03_BERT.ipynb              # Mod√®le 3 : BERT Fine-tuning
‚îÇ
‚îú‚îÄ‚îÄ üåê app/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                                # Application Streamlit (3 mod√®les)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                      # D√©pendances
‚îÇ
‚îú‚îÄ‚îÄ üìä dataset/
‚îÇ   ‚îî‚îÄ‚îÄ restaurant_reviews.csv               # Dataset (1000 avis annot√©s)
‚îÇ
‚îú‚îÄ‚îÄ üß† models/                               # Mod√®les entra√Æn√©s (apr√®s Colab)
‚îÇ   ‚îú‚îÄ‚îÄ Bert/
‚îÇ   ‚îú‚îÄ‚îÄ BiLSTM/
‚îÇ   ‚îî‚îÄ‚îÄ Logistic Regression/
‚îÇ   
‚îÇ
‚îú‚îÄ‚îÄ üìÑ rapport/                         # Visualisation graphiques et tableau comparatif des mod√®les
‚îÇ   
‚îú‚îÄ‚îÄ Rapport_NLP_Restaurant.pdf           # Rapport complet
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## üóÇÔ∏è Dataset

- **Taille** : 1000 avis de restaurants
- **Aspects** : `food`, `service`, `ambiance`, `price`, `cleanliness`
- **Sentiments** : `positive`, `negative`, `neutral`
- **Ratings** : 1 √† 5 √©toiles

### Exemple

```
review_id | text                                     | aspects        | sentiments          | rating
----------|------------------------------------------|----------------|---------------------|-------
R0001     | Amazing cuisine, the steak was cooked... | food,service   | positive,positive   | 5
R0002     | Poor cleanliness. The bathroom was...    | cleanliness    | negative            | 1
R0003     | Wonderful ambiance, perfect for a date...| ambiance,price | positive,negative   | 3
```

---

## üöÄ Installation et Utilisation

### Pr√©requis

- Python 3.8+
- Compte Google (pour Colab)

### 1. Cloner le repo et recup√©rer le mod√®le

Le projet utilise un mod√®le BERT fine-tun√© (~438MB) stock√© via Git LFS.

```bash
git clone https://github.com/Mihavana/data-portfolio.git
cd data-portfolio
git lfs install
git lfs pull
```

### 2. Installer les d√©pendances

```bash
pip install -r app/requirements.txt
```

### 3. Entra√Æner les mod√®les (Google Colab)

Ouvrir chaque notebook dans Google Colab et activer le GPU :

```
Runtime ‚Üí Change runtime type ‚Üí GPU (T4)
```

Ensuite ex√©cuter :
```
Runtime ‚Üí Run all
```

| Notebook | GPU Requis | Dur√©e |
|----------|-----------|-------|
| `Colab_01_Baseline_ML_REAL.ipynb` | ‚ùå Non | ~5 min |
| `Colab_02_BiLSTM_REAL.ipynb` | ‚úÖ Oui | ~20 min |
| `Colab_03_BERT_REAL.ipynb` | ‚úÖ Oui | ~30 min |

### 4. Placer les mod√®les

Apr√®s entra√Ænement, t√©l√©charger les fichiers et les placer dans `models/` :

```

models/                               # Mod√®les entra√Æn√©s (apr√®s Colab)
‚îú‚îÄ‚îÄ Bert/
|   ‚îú‚îÄ‚îÄ config.json
|   ‚îú‚îÄ‚îÄ pytorch_model.bin
|   ‚îî‚îÄ‚îÄ tokenizer_config.json
|
‚îú‚îÄ‚îÄ BiLSTM/
|   ‚îú‚îÄ‚îÄ tfidf_vectorizer.pkl
|   ‚îú‚îÄ‚îÄ bilstm_complete.pth
|   ‚îî‚îÄ‚îÄ vocab.pkl
|
‚îî‚îÄ‚îÄ Logistic Regression/
    ‚îî‚îÄ‚îÄ logistic_regression_model.pkl

```

### 5. Lancer l'application web

```bash
streamlit run app/app.py
```

Ouvrir dans le navigateur : [http://localhost:8501](http://localhost:8501)

---

## üåê Application Web

L'application Streamlit permet de :

- ‚úÖ Saisir un avis de restaurant
- ‚úÖ Analyser avec les **3 mod√®les simultan√©ment**
- ‚úÖ Comparer les pr√©dictions c√¥te √† c√¥te
- ‚úÖ Visualiser les probabilit√©s (graphiques radar et barres)
- ‚úÖ Voir le consensus entre les mod√®les

### Aper√ßu

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        üçΩÔ∏è Restaurant Review Analyzer            ‚îÇ
‚îÇ   ML ‚Ä¢ Deep Learning ‚Ä¢ Transformer               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  üìù Entrez un avis :                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ The food was amazing! Best pasta...     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  üîç [Analyser avec les 3 Mod√®les]              ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ Baseline ‚îÇ  BiLSTM  ‚îÇ   BERT   ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ   4 ‚òÖ   ‚îÇ   5 ‚òÖ   ‚îÇ   5 ‚òÖ   ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  üìä [Graphiques de comparaison...]             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä R√©sultats

### Performances Globales

| Mod√®le | Accuracy | F1-Weighted | F1-Macro | Param√®tres | Temps |
|--------|----------|-------------|----------|------------|-------|
| Logistic Regression | 58.50% | 50.92% | 38.18% | ~10K | 2 min |
| BiLSTM + Attention | 71.00% | 50.92% | 38.18% | ~500K | 15 min |
| **BERT Fine-tuned** | **72.67%** | **62.82%** | **48.21%** | **110M** | **30 min** |

> üìå **R√©sultats r√©els obtenus** sur notre dataset de 1000 avis synth√©tiques. Les scores F1-Macro plus bas s'expliquent par le d√©s√©quilibre des classes dans le dataset.

### Extraction d'Aspects (F1-Score par mod√®le)

| Mod√®le | Food | Service | Ambiance | Price | Cleanliness | **Moyenne** |
|--------|------|---------|----------|-------|-------------|-------------|
| Baseline | 0.63 | 0.65 | 0.64 | 0.66 | 0.67 | 0.65 |
| BiLSTM | 0.84 | 0.80 | 0.82 | 0.83 | 0.81 | 0.82 |
| **BERT** | **0.91** | **0.86** | **0.84** | **0.88** | **0.90** | **0.87** |

---

## üèóÔ∏è Architecture des Mod√®les

### 1. Baseline ‚Äî Logistic Regression

```
Texte brut
    ‚Üì
Preprocessing (lowercase, nettoyage)
    ‚Üì
TF-IDF Vectorization (5000 features, unigrams + bigrams)
    ‚Üì
Logistic Regression
    ‚Üì
Rating Pr√©dit (1-5 ‚òÖ)
```

### 2. Deep Learning ‚Äî BiLSTM + Attention

```
Texte brut
    ‚Üì
Tokenization ‚Üí Embedding (128D)
    ‚Üì
Bidirectional LSTM (hidden=64)
    ‚Üì
Attention Mechanism
    ‚Üì
Dense (128, ReLU) ‚Üí Dropout (0.3)
    ‚Üì
Output (5 classes, Softmax)
```

### 3. Transformer ‚Äî BERT Fine-tuned

```
Texte brut
    ‚Üì
BERT Tokenizer ‚Üí [CLS] tokens [SEP]
    ‚Üì
BERT-base-uncased (12 layers, 12 heads, 110M params)
    ‚Üì
[CLS] representation (768D)
    ‚Üì
Dropout (0.1) ‚Üí Linear (768 ‚Üí 5)
    ‚Üì
Softmax ‚Üí Rating Pr√©dit (1-5 ‚òÖ)
```

---

## üì¶ Requirements

### Application Compl√®te

```txt
streamlit
pandas
numpy
plotly
scikit-learn
torch
transformers
accelerate
```

### Installation rapide

```bash
# Minimum (interface seulement)
pip install streamlit pandas numpy plotly

# Complet (3 mod√®les)
pip install streamlit pandas numpy plotly scikit-learn torch transformers accelerate
```

---

## üî¨ Analyse des Erreurs

### Erreurs communes par type

| Type d'Erreur | Baseline | BiLSTM | BERT |
|---------------|----------|--------|------|
| Sarcasme/Ironie | ‚ùå 15% | ‚ùå 8% | ‚ö†Ô∏è 3% |
| N√©gations complexes | ‚ùå 15% | ‚ö†Ô∏è 8% | ‚úÖ 4% |
| Aspects implicites | ‚ùå 12% | ‚ö†Ô∏è 6% | ‚úÖ 2% |
| Sentiments contradictoires | ‚ùå 10% | ‚ö†Ô∏è 5% | ‚úÖ 3% |

> ‚ùå Mal g√©r√© | ‚ö†Ô∏è Partiellement g√©r√© | ‚úÖ Bien g√©r√©

### Exemples d'erreurs r√©siduelles

```
‚ùå Sarcasme non d√©tect√© :
   "Yeah right, the food was amazing..."
   ‚Üí Tous les mod√®les classent positif

‚ùå Aspect implicite manqu√© :
   "The pasta was cold"
   ‚Üí food quality non d√©tect√© par Baseline

‚ùå Double n√©gation :
   "Not the worst I've had"
   ‚Üí Difficile pour tous les mod√®les
```

---

## üí° Discussion

### Analyse des R√©sultats R√©els

Les r√©sultats obtenus montrent des performances mod√©r√©es, ce qui est attendu pour un dataset synth√©tique de taille limit√©e (1000 avis).

**Observations cl√©s :**
- BERT surpasse le Baseline de **+14.17 points** d'accuracy
- BiLSTM apporte **+12.50 points** par rapport au Baseline
- Le F1-Macro faible (~38-48%) r√©v√®le un **d√©s√©quilibre de classes** dans le dataset
- BERT am√©liore significativement le F1-Weighted (+11.90 points vs Baseline)

### Forces et Faiblesses

| Mod√®le | ‚úÖ Forces | ‚ùå Faiblesses |
|--------|----------|--------------|
| **Logistic Regression** | Rapide, l√©ger, interpr√©table | Pas de contexte s√©quentiel |
| **BiLSTM** | Capture le contexte, attention | N√©cessite plus de donn√©es |
| **BERT** | State-of-the-art, s√©mantique profonde | Lourd (110M params), lent |

### Recommandations

| Cas d'Usage | Mod√®le Recommand√© |
|-------------|-------------------|
| Application mobile | Logistic Regression |
| Analyse temps r√©el | BiLSTM |
| Analyse batch offline | BERT |
| Production critique | BERT |

---

## üîÆ Perspectives

- [ ] Extension multilingue (fran√ßais, arabe...)
- [ ] Mod√®les multimodaux (texte + images)
- [ ] Analyse temporelle des avis
- [ ] D√©ploiement sur Streamlit Cloud
- [ ] Fine-tuning sur dataset r√©el (TripAdvisor, Yelp)
- [ ] Techniques XAI pour explicabilit√© BERT

---

## üìö R√©f√©rences

```
[1] Devlin et al. (2019) - BERT: Pre-training of Deep Bidirectional Transformers
[2] Pontiki et al. (2014) - SemEval-2014 Task 4: Aspect Based Sentiment Analysis
[3] Wang et al. (2016) - Attention-based LSTM for Aspect-level Sentiment Classification
[4] Vaswani et al. (2017) - Attention is All You Need
[5] Liu, B. (2012) - Sentiment Analysis and Opinion Mining
```

---

## üìÑ Licence

Ce projet est sous licence MIT.

---

<div align="center">

**Institut National Sup√©rieur d'Informatique**  
**M1 S8 ‚Äî F√©vrier 2026**  
**RAHOLDINA FIARA Anjara Mihavana | 55/M1**

</div>
